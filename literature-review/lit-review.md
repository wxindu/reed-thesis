# Literature Review

* * *

- **Author:** Amy Orben and Andrew K. Przybylski
- **Year:** 2019
- **Title:** *The association between adolescent well-being and digital technology use*
- **Summary:** The paper examines correlational evidence for the effects of digital technology on adolescents using **Specification curve analysis (SCA)** across *three* large-scale social datasets, and found a resulted effect that's small and suggested that the effects are too small to warrant policy change. 
- **How does this relate?** This paper inspires the thesis. The method **SCA** seems to be misused in the paper. We'd like to focus on the statistical method and possibly figure out the correct way to conduct the study that's done in this paper. 
- **Link:** https://doi.org/10.1038/s41562-018-0506-1

* * *

- **Author:** Uri Simonsohn, Joseph P. Simmons and Leif D. Nelson
- **Year:** 2015
- **Title:** Specification Curve: Descriptive and Inferential Statistics on All Reasonable Specifications
- **Summary:** Proposed SCA
- **How does this relate?** The model used in Orben's paper. 
- **Link:** https://doi.org/10.2139/ssrn.2694998

* * *

## Method Related

- **Author:** Andrew Gelman and Eric Loken
- **Year:** 2013
- **Title:** The garden of forking paths: Why multiple comparisons can be a problem, even when there is no "fishing expedition" or "p-hacking" and the research hypothesis was posited ahead of time
- **Summary:** The paper discusses about how multiple comparisons can be a problem even when the researchers are not purposefully or consciously performing "finishing expedition" or "p-hacking". One of the main issue is that, the *scientific* hypothesis can correspond to multiple *statistical* hypothesis. There can be a large number of *potential* comparisons when the details of data analysis are highly contingent on data. It's not that the results of such study are not valid, but that the type evidence provided by the result may not be as strong as the researchers believe to be. 
- **How does this relate?** The paper addresses one important point, that while some researchers may be consciouly conducting inappropriate data analysis for significant results, other researchers who thought of themselves as following the correct rules and steps may unconsciouly make mistakes and conduct data analysis where a large number of potential comparisons are possible. This is related to the way Amy Orben was conducting the study using SCA, where she studies the correlation between *technology use* and *teen well-being*. Seemingly this is testing on one hypothesis, however based on her selection of variables, it is in fact again a combination of multiple statistical hypothesis. For example, both TV use and social media use are considered as alternatable options for representing "technology use", but with simply intuition one can suspect the TV use and social media use can be expressing very different information of how one is using technology and they could be related to teen well-being in total different way. The fact that she found no large correlation could, possibly but we don't know, be caused by correlation in opposite direction that's canceling out each other. "Technology use" is a very broad term to use and can be understood in a lot of alternative way. This is *not* really a single analysis on the data. 

* * *

- **Author:** Wolfgang Forstmeier, Eric-Jan Wagenmakers and Timothy H. Parker
- **Year:** 2017
- **Title:** Detecting and avoiding likely false-positive findings â€“ a practical guide
- **Summary:** Discusses about the replication crisis, the sources of errors and possible solutions
- **Hoe does this relate?** In the paper the SCA was briefly mentioned and discussed. In this paper, the SCA was described as "try all versions to examine robustness of findings". One other paper (Steegen *et al.*, 2016 was mentioned and seems to perform similar method (or method for similar purpose) as SCA
- **Link:** https://doi.org/10.1111/brv.12315

* * *

- **Author:** Julia M. Rohrer, Boris Egloff, Stefan C. Schmukle
- **Year:** 2017
- **Title:** Probing Birth-Order Effects on Narrow Traits Using Specification-Curve Analysis
- **Summary:** Another psychology study used SCA
- **How does this relate?** This paper is cited by Orben 2019. It uses the same SCA method proposed by Simonsohn et al. Still need to determine whether or not the SCA is used correctly in this paper. 
- **Link:** https://doi.org/10.1177/0956797617723726

* * *

## Scientific Question Related

