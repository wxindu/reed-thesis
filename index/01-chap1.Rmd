# SCA and Its Applications
\par In this chapter, we focus on the Specification-Curve Analysis and its existing applications. We discuss the details of conducting an appropriate SCA and then provide a description of two existing applications of SCA.  

## Specification-Curve Analysis

\par Conducting a specification-curve analysis involves three steps: (1) Identifying the set of specifications, (2) Estimate all specifications and construct a descriptive specification curve, and (3) Conduct inferential analysis on a specification curve. This section discusses the details in each step, along with the important assumptions and concepts of the method. 

### Specifications

\par The first step of conducting a Specification-Curve Analysis is to enumerate the set of specifications to be considered. Before choosing our specifications, it's important to first understand the type of specifications an SCA will be working with. Specifications usually refer to the decisions made by researchers while conducting a scientific study. Those may include decisions on deciding on a specific research question/statistical hypothesis, choice of analysis method, operational decisions during the modeling process, etc. The Specification-Curve Analysis works with a specific set of specifications: the set of specifications which are (1) consistent with the underlying theory, (2) expected to be statistically valid, (3) are not redundant with other specifications in the set. The specifications used in an SCA should be valid and non-redundant as determined by the researchers working on the study. Commonly, different researchers can have disagreements over specifications. When conducting an SCA, the researchers need only to consider the set of valid specifications in their perspective. If there are lots of overlaps between the valid specifications identified by different researchers, the results of the two SCA’s will be similar. If the two sets hardly or even never overlap, the results of two SCA’s would expectedly be very different. As long as SCA's are applied appropriately, such a difference is likely not due to chance but may imply something fundamentally different between the different sets of the underlying theory.

\par One important concept about the Specification-Curve Analysis is that the method only works with specifications that are operationalization decisions, the decisions that do not affect the underlying theory but may affect the outcomes of the result. Say we are conducting an SCA studying the relationship between Y and X. SCA can work with specifications such as, “Do a log transformation on variable X”, “Exclude three outliers”, “Include variable K as control variable”,  “Add an intersection term between X and K”, or “Do a logit model instead of a probit model”. Such decisions do not change the statistical hypothesis or research question proposed beforehand. Instead, they can change model outputs and potentially lead to different analysis results. In the other words, these specifications all focus on the type of operations that do not change the main characters and background in the story but may make small differences that can lead to a different story ending. SCA does not work with specifications that are based on different underlying theories. For example, say we want to study the relationship between class performance and hair color, where the hair color refers to the natural hair color that is determined by genes. Using a variable that also considers dyed hair color would not be appropriate since the action of dyeing hair and the choices of colors can reveal information regarding personalities. The relationship between class performance and this variable can be different than the story we want to tell. Thus, the variable "appearance hair color" will be an inappropriate specification to use for conducting an SCA on this research question. 

```{r StudyDesign, fig.cap="Visualization of scientific study steps", out.width = 450, echo = FALSE}
include_graphics(path = "figure/studyDesign.PNG")
```

\par A visualization may help with understanding this idea of specifications. Figure \@ref(fig:StudyDesign) presents as a tree the specifications that can be made by researchers when conducting a scientific study. In general, the researchers start with identifying a general area of interest (1) and then look for general topics that may be studied in the area (2). It is then possible to propose specific research questions, or statistical hypotheses in some cases(3). Once a specific question of interest is determined, an experiment may be conducted for data collection, or existing datasets may be used for later analysis (4). With data collected, researchers may make a set of operational decisions on data and model (5). After all the steps are finished, the researchers collect the model outputs and can move to an analysis of the results. Each node on the tree represents a distinct decision made by the researcher. Each leaf of the tree represents essentially a unique set of research outcomes that can be produced by a specific set of decisions made along the way. When conducting an SCA, only the specifications inside one of the boxes of operational decisions are varied, and only one set of the outputs based on the same underlying theory and modeling is analyzed. For example, a psychologist may be interested in studying the relationship between personal appearance and well-being. This would be a general area of interest. To conduct a study, the psychologist may then come up with several general topics, such as the relationship between personal appearance and mental health or the relationship between personal appearance and physical health. After careful consideration, the psychologist decides to focus on the first topic proposed. Within this general topic, multiple specific research questions can be proposed, which may include: "What is the relationship between hair color and teenager mental health", "What is the relationship between piercing and mental health", etc. After examining the existing literature, the psychologist decides to study specifically the relationship between hair color and teen mental health. Among the different ways of collecting data, the psychologist decides to conduct an observational study on hair color vs. teenager mental health. The psychologist then collects data and work on modeling and analysis. If to conduct an SCA in this study, the psychologist must only consider the specific set of outputs for the study of hair color vs. teenager mental health, as specified in the following figure: 

```{r StudyDesignEX, fig.cap="Visualization of scientific study steps", out.width = 450, echo = FALSE}
include_graphics(path = "figure/studyDesignSCA.png")
```

\par While the other decisions can be made along with an appropriate order that allows them to be connected as nodes being connected by branches of a tree, the operational decisions are more complicated. There are often different types of operational decisions, and not all combinations of operational decisions make sense in actual modeling process. Figure \@ref(fig:OpeDec_Real) provides a visualization of the operational decisions: 

```{r OpeDecReal, fig.cap="Visualization of Operational Decisions", out.width = 450, echo = FALSE}
include_graphics(path = "figure/OpeDec_Real.png")
```

\par In this figure, each node represents a unique decision of the type that could be made by the researchers, and the branches connect appropriate combinations of decisions. Following the branches in different ways can lead to different combinations of these operational decisions, and will produce sets of unique models which then produce a set of possible model outputs. 

\par Note that in figure \@ref(fig:OpeDecReal), not all nodes are connected to nodes in the next group. In real life, not all combinations of operational decisions are appropriate to be applied together. For example, if a log transformation on a variable is performed, some data points may not be considered outliers anymore and thus not removed. Thus this variable transformation decision will not be used in combination with some of the outlier decisions, and at least two nodes will not be connected by any branches. Ideally, the SCA will be working with only such appropriate combinations of operational specifications. But among the existing application of SCA, after enumerating the specifications of each type, all combinations of the enumerated specifications are considered, which can be visualized as in the following figure: 

```{r OpeDecSCA, fig.cap="Visualization of Operational Decisions considered in existing applications", out.width = 450, echo = FALSE}
include_graphics(path = "figure/OpeDec_SCA.png")
```


### Specification Curve

\par The next step will be building a specification curve. After determining the specifications, a set of combinations of the specifications can be determined, where each combination leads to a different model to be run. Here we describe how the existing applications tend to generate combinations of specifications. Say a group of researchers considered only a set of model type decisions and a set of outlier decisions as 1) Use regression model A, 2) Use regression model B instead of A, 3) Use variable X as the independent variable, 4) Remove outliers from X and use the new variable X' as the independent variable. There will be four combinations of the two types of specifications and will produce specification models as: 

\begin{enumerate}
  \item Model A with independent variable X
  \item Model A with independent variable X'
  \item Model B with independent variable X
  \item Model B with independent variable X'
\end{enumerate}

\par When there are lots of variables involved, the list of specifications can be large, which can result in a huge number of combinations of specifications. This makes the set of specification models to be huge and difficult to computationally work with. For example, say we are working on a dataset with 10 variables, and say we identified: 1) 2 model decisions, 2) 20 variable transformation decisions, 3) 10 outlier decisions, and 4) 10 interaction decisions, this will result in 4000 different specification models. Running all 4000 models can take a while and can be computationally expensive with complicated model forms. It is also not rare for the number of variables to be much larger and the model form can be much more complicated in real life. In case of having a large number of specification models that brings computationally difficulty, a random subset of the specification models can be used instead. 

\par Now all the models have been determined, the next step is to run all the models and extract the point estimates from each of the models. In the case of linear regressions, the extracted point estimates are generally the $\beta$ estimates from each model. The estimates are then plotted as a curve, where the vertical axis refers to their numerical values, and the horizontal axis refers to the set of specifications that generated the specific model for this estimate. 

\newpage

```{r SC, fig.cap="Specification Curve", out.width = 450, echo = FALSE}
include_graphics(path = "figure/SC.PNG")
```

\newpage

\par As shown in Figure \@ref(fig:SC), a descriptive specification curve encompasses two parts: the top plot of a curve, and the bottom plot with lines and dots on it. In the top plot, the curve is the curve of the estimates from each of the models, ordered from lowest value to highest value. The vertical axis is the numerical value for the estimates, and the values on the horizontal axis represent the set of specifications used for this specific model, represented by dots in the bottom plot. In the bottom half of the plot, each dot represents the usage of a specification. The vertical axis is the name of the specifications. For example, the first dot on the curve is an estimate from a model using the specifications: "No controlling for year", "Main effect and no interaction", "Log Damage instead of Damage (in \$)", "log-linear model instead of negative binomial model", "Use 0/1 for feminity instead of a 1-10 scaling", "Drop three hurricanes with highest damages as outliers", and "Drop two hurricanes with highest deaths as outliers". 

\par Overall, it is possible to visualize from a specification curve plot if there exists a certain pattern relating to the choice of specifications and the corresponding estimation. For example, in the plot shown above, negative point estimates appear to require an idiosyncratic set of specifications. Also included in the plot is the indication of the models with statistically significant estimation. From the plot, it is possible to visualize if the statistical significance appears to be happening purely by chance, or if there appears to be some real relationship. For example, in this case, of the 1728 specification models, only 37 obtained statistically significant estimates. Overall, this specification curve may be suggesting that a non-statistically significant result is robust under alternative specifications. 

### Specification-Curve Analysis

\par The last step of an SCA is the statistical inference on the single specification curve result. The question for an inferential analysis, as stated by the authors, is “\emph{Considering the full set of reasonable specifications jointly, how inconsistent are the results with the null hypothesis of no effect?}”. Although more formal and detailed guidance of conducting an inferential analysis for a single specification curve is desired, the authors only provided suggestions on how an inferential analysis may be performed. It was suggested that using the technique of resampling, one can generate an expected distribution of the
specification curves when the null hypothesis is true. The examples provided in the paper all used the permutation technique for resampling of the data, and it was suggested that a bootstrapping technique can be applied for studies without random assignment.

Once a distribution of specification curves is obtained, three test statistics are proposed to do the inferential analysis, and the authors did not decide on which ones to be more favored: 1) the median overall point estimate from the specification curve, 2) the share of estimates in specification curve that are of the dominant sign, 3) the share that is of the dominant sign and also statistically significant (p < 0.05). The dominant sign here refers to the sign of the majority of estimates. If the majority of the estimates in an SCA have a positive sign, then the dominant sign will be positive. Generally, we would not expect half the estimates to be positive and the rest to be negative, as the different models are not fundamentally different but rather similar at most places. This test statistic serves as a summary statistic of the entire specification curve. So instead of a "distribution of curves", the analysis works with the distribution of the test statistics from the curves. The p-value extracted, as claimed by the authors, will provide an answer to the proposed inferential question. One thing worth noting is the interpretation of the p-value. Although not specified in the main text, in the examples listed in the paper, the actual numerical value of the test statistic is not considered meaningful. For example, the authors did not use the magnitude of the median estimate for inference on effect size. The p-values are used for indicating how robust the effects are in response to changes in specifications. A low p-value indicates that the effect is robust in response to changes in specifications. This suggests that the result is inconsistent with the null hypothesis of no effect, indicates a strong sign for the existence of a statistically significant relationship. A high p-value indicates consistency with the null hypothesis of no effect, suggesting the failure to reject the hypothesis that no relationship exists.

## Applications of SCA

\par The paper that proposed SCA is not yet published, however, the method has already been widely applied in the field of Psychology. A few published studies have used SCA to study topics including the effect of social media on adolescent life satisfaction [@Orben10226], the relationship between adolescent mental health and technology use [@Orben2019], the association between digital-screen engagement & adolescent well-being [@OrbenScreen], effect of birth-order position on personality [@Rohrer], etc. In this section, we focus on two of the applications and discuss the design of SCA analyses in the studies. 

### Adolescent Mental Health and Technology Use

\par This study conducted by Orben and Przybylski attempt to assess the association between digital technology use and adolescent well-being using 3 large-scale social datasets: Monitoring the Future (MTF), Youth Risk and Behaviour Survey (YRBS), and Millennium Cohort Study (MCS). The data were collected from studies of the same names, and encompass survey answers from adolescents and relatives on a variety of topics over a long period. For each of the three datasets, Orben identified a set of specifications and conducted SCA analysis for the research question of “the association between adolescent well-being and digital technology use”. In this section, we summarize Orben’s approach, main steps, and main findings. A detailed assessment and critique of the usage of SCA in this study will be provided in Chapter 2.

\par \textbf{Identifying Specifications} The first step to conduct an SCA analysis is to identify the set of reasonable specifications. In this study, there are mainly three types of specifications considered: 1. alternative variables representing adolescent mental well-being; 2. alternative variables representing digital technology use by individuals; 3. whether or not to include a set of predetermined control variables. The model is set in default to be linear regression. When the control variables are in use, the model will be multivariate linear regression, otherwise, it will be just simple linear regression. A table including all specifications determined by Orben in each dataset will be included in the Appendix. Here we provide an example: the list of alternative variables to represent “digital technology use” for MCS includes: “Whether or not own a computer at home”, “Hours of social media use on a normal weekday”, “time on TV viewing on a weekday”, etc. A total number of 372 specification models were determined for YRBS, 40,966 specification models were determined for MTF, and 603,979,752 specification models were determined for MCS. In the case of MCS, and a random subset of the specifications models with size 20,004 was used instead for computational purposes. 

\par \textbf{Single SCA and analysis} After determining the set of specifications for each of the three datasets, three specification curves were generated. For each fitted specification model, the estimate of $\beta$ on the variable representing “technology use” was collected and presented on the curve. Instead of focusing on the curves, Orben analyzed the summarized statistics from the specification curves. She focused on the sign and magnitude of the median $\beta$ estimates and concluded that a small negative relationship is determined for each of the three datasets. A full table of results will be included. 

\par \textbf{Bootstrapping test and inference} The last step is to conduct inference on the SCA result. Orben performed a bootstrapping test and generated 500 specification curves on bootstrapped data. The inference was performed using all three test statistics as suggested by Simonsohn et al. The p-values found were all approximately 0. As a result of the test, she concluded that evidence has been found supporting the negative relationship between digital technology use and adolescent well-being.

\par \textbf{Others} In addition to the SCA analysis on the research question, Orben performed additional SCA analyses on relationship between adolescent mental well-being and several other variables of interest, including binge-drinking, smoking marijuana, being bullied, arrested, perceived weight, eating potatoes, etc.. The mean estimates on technology use variables is compared with these results, and it’s suggested that the small negative effect of technology use on adolescent mental well-being may be too
small to warrant policy changes. 

\par Overall, a small negative relationship between adolescent well-being and digital technology use was found, and the effect is suggested to be small enough such that no policy changes may be needed. However, several major issues exist in the application of SCA in this study, and the reliability of this result can be questionable. In Chapter 2, a description of the full replication of the study along with detailed assessments and critiques of this study will be provided.

### Birth-Order Position and Personality

\par Rohrer et al. applied SCA and studied the effect of birth-order position on personality. The data used in this study came from the SOEP, which is an ongoing study of private households in Germany and their members. The study focuses on multiple research questions of interest, studying the effect of birth-order position on 11 personality variables, including life satisfaction, interpersonal trust, intellect, etc. In comparison to the description of Orben's study, we will focus less on the details but instead focus on its main steps of constructing the SCA's. A comparison between this application and Orben's application will be provided in the next chapter. 

\par \textbf{Identifying Specifications} An SCA was run for each of the 11 research questions. A different set of specifications was determined for each of the SCA. The paper provided a list of the model specifications determined: 

\begin{enumerate}
    \item Different ways to measure the personality variable; 
    \item Use raw scores or age-adjusted scores; 
    \item Within-family or between-family analyses; 
    \item Which definition of birth-order position to use: the social definition or the more restrictive definition limited to full siblings; 
    \item Differentiation of each birth-order position within a sibship (e.g., first, second, third) or differentiation only of firstborn from later positions; 
    \item Inclusion of all sibships or sibships with spacing does not exceed 5 years, or sibships with sibling spacing exceeded 1.5 years but did not exceed 5 years between any two siblings; 
    \item Exclusion of any gender effects, the inclusion of the main effect of gender, or inclusion or both the main effect of gender and the interaction of birth-order position and gender; 
    \item Analysis of the complete sample, analysis of only individuals from sibships with 2 to 4 children, or separate analyses for sibships of 2, 3, and 4 children.
\end{enumerate}

\par Many of the specifications considered in this study are appropriate operational decisions, including outlier decisions and variable transformation decisions. It appears that some specifications identified may be based on the different underlying theories and/or different research questions. In the next chapter, we will discuss with more details of the choice of specifications in this study. 

\par \textbf{SCA and analysis} For most of the 11 SCAs, 720 specification models were determined, while two of them determined a larger number of specification models: 1440 and 2160. All models were run, and the estimates of the main effect were extracted for analysis. A permutation test is performed for inference, following the same procedure as performed in the examples provided by Simonsohn et al.  All three suggested test statistics were used. The p-values are then used for evidence of a statistically significant effect. 