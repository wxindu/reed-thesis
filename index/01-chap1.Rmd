# SCA and Its Applications

\par It has come to researchers' attention that, the minor decisions made by researchers along the way of performing a data analysis can have a larger effect on the final research output than expected. A dataset can be analyzed in lots of different ways as there are a great number of decisions that can be made by a researcher: which statistical test to perform, which variables to include, which transformation to make on variables, etc. And by making specific decisions along the way, such as "multiple comparison", it is possible to find a p-value of less than 0.05 on data with absolutely no relationship. This problem is often called "p-hacking" or "researcher degrees of freedom". A great number of recent studies looked into this problem closely, and it's been discovered that even if researchers are not consciously performing the action of "p-hacking", when the details in a data analysis are too contingent on data, there can still be the problem of multiple potential comparisons (cite Gelman and Loken 2013). It is now commonly realized that simply following the traditionally appropriate way to conduct a data analysis and look for a statistically significant p-value is no longer sufficient to produce reliable results. 

\par The decisions made by a researcher, or in the other term, the specifications, are often a small subset of a much larger set of valid specifications. Thus there can be great limitation on the conclusiveness of the results, as the results usually hinge on the selected specifications, and sometimes the selection of specifications are made under researchers' hope to produce a publishable exciting story. Methods have been proposed to work around with the existence of such problem, and one approach taken in social science is to consider the robustness of models in response to alternative specifications. It is the consideration that, assuming some alternative sets of specifications were chosen by the researchers, how would the different results agree with each other. From there it is possible to get a sense of how greatly the original result hinges on the choices of specifications. The one method that will be focused on in this thesis is the Specification-curve analysis (SCA), proposed by Simonsohn, Simmons, Nelson in 2015. SCA considers non-overlapping sets of reasonble specifications and the potential different conclusions that one can arrive on. The method provides a way to visualize the different results one can arrive based on the different choices of specifications and to have a general understanding on where the differences may orginate from. Most importantly, it provides an assessment of a model's robustness in response to changes in specifications. 

\par The few applications of SCA are all in the field of psychology. Several psychologists have applied this method on controversial topics which gather global attention. However, some usage of the method seens to be deviated from the original purpose of the method, and the conclusion drawn by the analysis remains questionable. One of the major application of SCA, the study of the association between adolescent well-being and digital technology use by Orben and Przybylski published on nature in 2019, is one of such applications. After a full replication of Orben's study, it's found that the main problems of this study lie in the misunderstanding of the type of specifications that SCA works with, and the inference of the SCA result. The replication and details on the problems will be discussed in Chapter 2. In the following sections, we will introduce in details about SCA, its existing applications, and Orben's application. 

\par (The thesis also focuses on... formal inference method for SCA? Potential improvement of the method?)


## Specification-Curve Analysis

\par Conducting a specification-curve analysis involves three steps: (1) Identifying set of specifications, (2) Estimate all specifications and construct a descriptive specification curve, (3) Conduct inferential analysis on a specification curve. This section discusses the details in each step, along with the important assumptions and concepts of the method.

### Specifications

\par The first step of conducting a Specification-Curve Analysis is to enumerate the set of specifications to be considered. Specficiation-Curve Analysis focuses on a specific set of specifications: the set of specifications which are (1) consistent with the underlying theory, (2) expected to be statistically valid, (3) are not redundant with other specifications in the set. The specifications used in a SCA should be the valid and non-redundant specifications considered by the researcher. It is common that different researchers have disagreements over specifications, and when conducting a SCA, a researcher needs only to consider the set of valid specifications in their own perspective. If there are lots of overlaps between two researchers' sets of valid specifications, the results of two SCA's should be similar. If the two sets hardly or even never overlap, the results of two SCA's would be different. And such difference between analyses' results would most likely not be difference happening by chance, but may be originated by something fundamentally different, maybe different underlying theory. 

\par One important concept about the Specification-Curve Analysis is that, the specifications considered in an SCA are all operationlization decisions, not theorizing decisions. Say we are conducting an SCA studying the relationship between Y and X. Some appropriate specifications to be used in an SCA can be, "Do a log transformation on variable X", "Exclude these three outliers", "Include variable K as control variable", "Add an intersection term between X and K", or "Do a logit model instead of a probit model". These specifications all focus on, after the underlying theory is determine and the statistical question has been stated, what type of operations I can do to my model that does not change the main characters in the story but may make small differences that can affect the story ending. But specifications that are based on different underlying theory are not the type of specifications that an SCA can work with. For example, if the question of interest is the relationship between class performance and hair color, where the hair color was intended to be the natural hair color that is determined by genes, using a variable that also considers dyed hair color would not be appropriate, since the action of dyeing hair reveals information regarding personalities, and the choice of hair coloring also reveals information regarding personalities. The relationship between this class performance and this variable will be telling a different story. It would thus not be appropriate in this case to consider the interchange of these two variables as an appropriate specification, as the underlying theories are different. 

\par Note that sometimes the set of specifications can be huge and difficult to computationally work with. For example, say we are working on a dataset with 10 variables, and say we have: 1) 2 possible regression model, 2) 2 ways of transforming each of the 10 variables, 3) 3 ways for each variable to deal with outliers, and 4) 10 ways of adding interaction terms, this will result in 12000 different models to run with each model are built based on a different set of specifications. And in reality, the number of variables can be much larger than 10, and the model form can be much more complicated. In case if the set of specifications is too large, it was proposed that a random subset of the specifications can be used instead. 

### Specification Curve

\par The next step will be running estimation on the set of different models based on the enumerated specifications, and then constructing a specification curve. Shown below is an example of a specification curve (cite)

%```{r SpecCurv, fig.cap="Specification Curve", fig.width=6}
%include_graphics(path = "figure/specificationCurve.png")
%```
% To be edited

\par As shown in the graph, a descriptive specification curve encompasses two parts: the top plot of a curve, and the bottom plot with lines and dots on it. The curve is the curve of the estimates from each of the model, ordered from lowest value to highest value. In the bottom half of the plot, each dot represents the usage of a specification. The vertical axis are the specifications used. And for each dot on the curve, there is a corresponding column in the bottom plot. If a specification was used in the model that produced this specific estimation, there will be a dot in the column at the position matching with the specification name on the vertical axis. Therefore, overall, it is possible to visualize if there exist certain pattern in choice of combination of specifications and the corresponding estimation. Also included on plot is the indication of the models with statistcially significant estimation. From the plot it is possible to visualize if the statistical significance appears to be happening purely by chance, or if there appears to be some real relationship. If so, if the relationship appears robust under changes in specifications. 

### Specification-Curve Analysis

\par The last step of a SCA is the statistical inference. The question for an inferential analysis, as stated by the authors, is "\emph(Considering the full set of reasonable specifications jointly, how inconsistent are the results with the null hypothesis of no effect?)". No step-by-step instructions are given for a complete inferential analysis. It was suggested that using the technique of resampling, one can generate an expected distribution of specification curves when the null hypothesis is true. The examples provided in the paper all used the permutation technique, while it was suggested that a bootstrapping technique is also applicable for studies without random assignment. 

\par Three test statistics are proposed for the inferential analysis, but the authors do not specify which ones might be more favored: 1) the median overall point estimate from the specification curve, 2) the share of estimates in specification curve that are of the dominant sign, 3) the share that are of the dominant sign and also statistically significant (p < 0.05). The dominant sign here refer to the sign of the majority of estimates. If the majority of the estimates in a SCA have positive sign, then the dominant sign will be positive. Generally we would not expect half the estimates to be positive and the rest to be negative, as the different models are not fundamentally different but rather similar at most places. This test statistic performs as a summary of the entire specification curve, and the resampling procedure produces a null distribution of the test statistic. The p-value extracted, as claimed by the authors, will answer the inferential question we proposed. One thing worth noting is the interpretation of the p-value. In the examples listed in the paper, the actual numerical value of the test statistic are not meaningful. The p-value, however, indicates how robust the estimates are in response to changes in specifications. A low p-value indicates inconsistency with the null hypothesis of no effect, indicating strong sign for the existence of statistically significant relationship. A high p-value indicates consistency with the null hypothesis of no effect, suggesting the failure to reject the hypothesis that no relationship exist. 

## Applications of SCA

### Existing applications

### Orben's Application