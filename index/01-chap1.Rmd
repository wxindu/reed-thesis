# SCA and Its Applications

\par It has come to researchers’ attention that, the minor decisions made by researchers along the way of performing a data analysis can have a larger effect on the final research output than expected. A dataset can be analyzed in lots of different ways with the flexible decisions that a researcher can make: which statistical test to perform, which variables to include, which transformation to make on variables, etc. Certain "decisions" made, such as an action commonly called "multiple comparisons", ensures a statistically significant result to be found, even on data with absolutely no relationship. This problem is often called “p-hacking” or “researcher degrees of freedom”, and it's been found to be one of the major reasons for the replication problem in some fields. A great number of studies have studied these problems closely. It is now commonly realized that simply following the traditionally "appropriate" way to conduct data analysis and look for a statistically significant p-value is no longer sufficient to produce reliable results. 

\par Another term for the decisions made by a researcher while conducting a study is specifications. When conducting a single study, the specifications performed by a researcher are often a small subset of a much larger set of valid specifications. Thus there can be a great limitation on the conclusiveness of the results, as the results usually hinge on the selected specifications. Methods have been proposed to work around with the existence of such a problem, and one of the approaches taken in social science is to consider the robustness of models in response to alternative specifications. It considers that when alternative sets of specifications were performed by the researchers, how might the obtained results agree/differ with the original result. From there it is possible to get a sense of to which extends do the original result hinges on the choices of specifications. The one method that will be discussed in this thesis is the Specification-curve analysis (SCA), proposed by Simonsohn, Simmons, Nelson in 2015. SCA considers non-overlapping sets of reasonable specifications and the potential different conclusions that one can arrive on. The method provides a way to visualize the different results one can arrive based on the different choices of specifications and to have a general understanding of where the differences may originate from. Most importantly, it provides an assessment of a model’s robustness in response to changes in specifications.

\par The few applications of SCA are all in the field of psychology. Several psychologists have applied this method on controversial topics that gather global attention. However, some usage of the method seems to deviate from the original purpose of the method, and the conclusion drawn by the analysis remains questionable. One of the major application of SCA, the study of the association between adolescent well-being and digital technology use by Orben and Przybylski published on nature in  2019, is one of such applications. After a full replication of Orben’s study, it’s found that the main problems of this study lie in the misunderstanding of the type of specifications that SCA works with, and the inference of the SCA result. The replication and details of the problems will be discussed in Chapter 2. In the following sections, we will introduce in detail about SCA, its existing applications, and Orben’s application. 


## Specification-Curve Analysis

\par Conducting a specification-curve analysis involves three steps: (1) Identifying the set of specifications, (2) Estimate all specifications and construct a descriptive specification curve, and (3) Conduct inferential analysis on a specification curve. This section discusses the details in each step, along with the important assumptions and concepts of the method. 

### Specifications

\par The first step of conducting a Specification-Curve Analysis is to enumerate the set of specifications to be considered. Before choosing our specifications, it's important to first understand the type of specifications an SCA will be working with. Specification-Curve Analysis focuses on a specific set of specifications: the set of specifications which are (1) consistent with the underlying theory, (2) expected to be statistically valid, (3) are not redundant with other specifications in the set. The specifications used in an SCA should be the valid and non-redundant specifications as considered by the researcher. Commonly, different researchers have disagreements over specifications, and when conducting an SCA, a researcher needs only to consider the set of valid specifications in their perspective. If there are lots of overlaps between two researchers’ sets of valid specifications, the results of two SCA’s should be similar. If the two sets hardly or even never overlap, the results of two SCA’s would expectedly be very different. And when SCA's are applied appropriately, such a difference between analyses’ results are likely not happening by chance but could be originated by something fundamentally different, maybe different underlying theory.

\par One important concept about the Specification-Curve Analysis is that the specifications considered in an SCA are all operationalization decisions, not theorizing decisions. Say we are conducting an SCA studying the relationship between Y and X. Some appropriate specifications to be used in an SCA can be, “Do a log transformation on variable X”, “Exclude these three outliers”, “Include variable K as control variable”,  “Add an intersection term between X and K”, or “Do a logit model instead of a probit model”. These are decisions researchers can make after a statistical hypothesis has been stated, or a theory to be studied is determined. These specifications all focus on the type of operations researchers can do that does not change the main characters and background in the story, but may make small differences that can lead to a different story ending. Specifications that are based on different underlying theories are not the type of specifications that an SCA can work with. For example, say we want to study the relationship between class performance and hair color, where the hair color refers to the natural hair color that is determined by genes. Using a variable that also considers dyed hair color would not be appropriate since the action of dyeing hair and the choices of colors can reveal information regarding personalities. The relationship between class performance and this variable can be different than the story we want to tell. Thus, the variable "appearance hair color" will be an inappropriate specification to use for conducting an SCA on this research question. 

### Specification Curve

\par The next step will be building a specification curve. After determining the specifications, a set of combinations of the specifications can be determined, where each combination leads to a different model to be run. For example, say we determined the full list of specifications to be: 1) Use regression model A, 2) Use regression model B instead of A, 3) Use variable X as the independent variable, 4) Remove outliers from X and use the new variable X' as the independent variable. The specification models we can build are: 

\begin{enumerate}
  \item Model A with independent variable X
  \item Model A with independent variable X'
  \item Model B with independent variable X
  \item Model B with independent variable X'
\end{enumerate}
One can consider this step to be collecting all different combinations of specifications of different types. 

\par When the dataset is large and lots of data-processing have to be performed, the list of specifications can be large, which makes the set of specification models to be huge and difficult to computationally work with. For example, say we are working on a dataset with 10 variables, and say we have: 1) 2 choices of regression model, 2) 2 ways of transforming each of the 10 variables, 3) 3 ways for each variable to deal with outliers, and 4) 10 ways of adding interaction terms, this will result in 12000 different specification models. Running all 12000 models can be computationally intense and maybe difficult to perform in real life. It is also not rare for the number of variables to be much larger than 10 in real life, and the model form can be much more complicated and computationally difficult. In this case, a random subset of the specification models can be used instead. 

\par Now all the models have been determined, the next step is to run all the models and extract the point estimates from each of the models. In the case of linear regressions, the extracted point estimates are most likely to be the estimates of $\beta$ from each model. The estimates are then plotted as a curve, where the vertical axis refers to their numerical values, and the horizontal axis refers to the set of specifications that generated the specific model for this estimate. 

```{r SC, fig.cap="Specification Curve", scale=0.1, echo = FALSE}
include_graphics(path = "figure/specificationCurve.png")
```

\par As shown in Figure \@ref(fig:SC), a descriptive specification curve encompasses two parts: the top plot of a curve, and the bottom plot with lines and dots on it. In the top plot, the curve is the curve of the estimates from each of the models, ordered from lowest value to highest value. The vertical axis is the numerical value for the estimates, and the values on the horizontal axis represent the set of specifications used for this specific model, represented by dots in the bottom plot. In the bottom half of the plot, each dot represents the usage of a specification. The vertical axis is the name of the specifications. For example, the first dot on the curve is an estimate from a model using the specifications: "No controlling for year", "Main effect and no interaction", "Log Damage instead of Damage (in \$)", "log-linear model instead of negative binomial model", "Use 0/1 for feminity instead of a 1-10 scaling", "Drop three hurricanes with highest damages as outliers", and "Drop two hurricanes with highest deaths as outliers". 

\par Overall, it is possible to visualize from a specification curve plot if there exists a certain pattern relating to the choice of specifications and the corresponding estimation. For example, in the plot shown above, negative point estimates appear to require an idiosyncratic set of specifications. Also included in the plot is the indication of the models with statistically significant estimation. From the plot, it is possible to visualize if the statistical significance appears to be happening purely by chance, or if there appears to be some real relationship. For example, in this case, of the 1728 specification models, only 37 obtained statistically significant estimates. Overall, this specification curve may be suggesting that a non-statistically significant result is robust under alternative specifications. 

### Specification-Curve Analysis

\par The last step of an SCA is the statistical inference on the single specification curve result. The question for an inferential analysis, as stated by the authors, is “\emph{Considering the full set of reasonable specifications jointly, how inconsistent are the results with the null hypothesis of no effect?}”. Although more formal and detailed guidance of conducting an inferential analysis for a single specification curve is desired, the authors only provided suggestions on how an inferential analysis may be performed. It was suggested that using the technique of resampling, one can generate an expected distribution of the
specification curves when the null hypothesis is true. The examples provided in the paper all used the permutation technique for resampling of the data, and it was suggested that a bootstrapping technique can be applied for studies without random assignment.

Once a distribution of specification curves is obtained, three test statistics are proposed to do the inferential analysis, and the authors did not decide on which ones to be more favored: 1) the median overall point estimate from the specification curve, 2) the share of estimates in specification curve that are of the dominant sign, 3) the share that is of the dominant sign and also statistically significant (p < 0.05). The dominant sign here refers to the sign of the majority of estimates. If the majority of the estimates in an SCA have a positive sign, then the dominant sign will be positive. Generally, we would not expect half the estimates to be positive and the rest to be negative, as the different models are not fundamentally different but rather similar at most places. This test statistic serves as a summary statistic of the entire specification curve. So instead of a "distribution of curves", the analysis works with the distribution of the test statistics from the curves. The p-value extracted, as claimed by the authors, will provide an answer to the proposed inferential question. One thing worth noting is the interpretation of the p-value. Although not specified in the main text, in the examples listed in the paper, the actual numerical value of the test statistic is not considered meaningful. For example, the authors did not use the magnitude of the median estimate for inference on effect size. The p-values are used for indicating how robust the effects are in response to changes in specifications. A low p-value indicates that the effect is robust in response to changes in specifications. This suggests that the result is inconsistent with the null hypothesis of no effect, indicates a strong sign for the existence of a statistically significant relationship. A high p-value indicates consistency with the null hypothesis of no effect, suggesting the failure to reject the hypothesis that no relationship exists.

## Applications of SCA

\par The paper that proposed SCA is not yet published, however, the method has already been widely applied in the field of Psychology. A few published studies have used SCA to study topics including the effect of social media on adolescent life satisfaction (Orben, Deinlin & Przybylski, 2019), relationship between adolescent mental health and technology use (Orben & Przybylski, 2019), association between digital-screen engagement & adolescent well-being (Orben & Przybylski), effect of birth-order position on personality (Rohrer, Egloff & Schmukle, 2017), etc. Among all the existing applications, Orben and her team have used the method most frequently, and some of their studies have received great attention. In this thesis, I will focus on their study on the association
between adolescent well-being and digital technology use, published on Nature in 2019.

### Orben's Application

\par This study conducted by Orben and Przybylski attempt to assess the association between digital technology use and adolescent well-being using 3 large-scale social datasets: Monitoring the Future (MTF), Youth Risk and Behaviour Survey (YRBS), and Millennium Cohort Study (MCS). The data were collected from studies of the same names, and encompass survey answers from adolescents and relatives on a variety of topics over a long period. For each of the three datasets, Orben identified a set of specifications and conducted SCA analysis for the research question of “the association between adolescent well-being and digital technology use”. In this section, we summarize Orben’s approach, main steps, and main findings. A detailed assessment and critique of the usage of SCA in this study will be provided in Chapter 2.

\par \textbf{Identifying Specifications} The first step to conduct an SCA analysis is to identify the set of reasonable specifications. In this study, there are mainly three types of specifications considered: 1. alternative variables representing adolescent mental well-being; 2. alternative variables representing digital technology use by individuals; 3. whether or not to include a set of predetermined control variables. The model is set in default to be linear regression. When the control variables are in use, the model will be multivariate linear regression, otherwise, it will be just simple linear regression. A table including all specifications determined by Orben in each dataset will be included in the Appendix. Here we provide an example: the list of alternative variables to represent “digital technology use” for MCS includes: “Whether or not own a computer at home”, “Hours of social media use on a normal weekday”, “time on TV viewing on a weekday”, etc. A total number of 372 specification models were determined for YRBS, 40,966 specification models were determined for MTF, and 603,979,752 specification models were determined for MCS. In the case of MCS, and a random subset of the specifications models with size 20,004 was used instead for computational purposes. 

\par \textbf{Single SCA and analysis} After determining the set of specifications for each of the three datasets, three specification curves were generated. For each fitted specification model, the estimate of $\beta$ on the variable representing “technology use” was collected and presented on the curve. Instead of focusing on the curves, Orben analyzed the summarized statistics from the specification curves. She focused on the sign and magnitude of the median $\beta$ estimates and concluded that a small negative relationship is determined for each of the three datasets. A full table of results will be included. 

\par \textbf{Bootstrapping test and inference} The last step is to conduct inference on the SCA result. Orben performed a bootstrapping test and generated 500 specification curves on bootstrapped data. The inference was performed using all three test statistics as suggested by Simonsohn et al. The p-values found were all approximately 0. As a result of the test, she concluded that evidence has been found supporting the negative relationship between digital technology use and adolescent well-being.

\par \textbf{Others} In addition to the SCA analysis on the research question, Orben performed additional SCA analyses on relationship between adolescent mental well-being and several other variables of interest, including binge-drinking, smoking marijuana, being bullied, arrested, perceived weight, eating potatoes, etc.. The mean estimates on technology use variables is compared with these results, and it’s suggested that the small negative effect of technology use on adolescent mental well-being may be too
small to warrant policy changes. 

\par Overall, a small negative relationship between adolescent well-being and digital technology use was found, and the effect is suggested to be small enough such that no policy changes may be needed. However, several major issues exist in the application of SCA in this study, and the reliability of this result can be questionable. In Chapter 2, a description of the full replication of the study along with detailed assessments and critiques of this study will be provided.